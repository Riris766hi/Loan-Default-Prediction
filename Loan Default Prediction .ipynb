{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loan Default Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # Visualization\n",
    "import seaborn as sns # For easier statistical plotting\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings. filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105471, 771)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"train_v2.csv\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f770</th>\n",
       "      <th>f771</th>\n",
       "      <th>f772</th>\n",
       "      <th>f773</th>\n",
       "      <th>f774</th>\n",
       "      <th>f775</th>\n",
       "      <th>f776</th>\n",
       "      <th>f777</th>\n",
       "      <th>f778</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>10</td>\n",
       "      <td>0.686842</td>\n",
       "      <td>1100</td>\n",
       "      <td>3</td>\n",
       "      <td>13699</td>\n",
       "      <td>7201.0</td>\n",
       "      <td>4949.0</td>\n",
       "      <td>126.75</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2.14</td>\n",
       "      <td>-1.54</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.7873</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>121</td>\n",
       "      <td>10</td>\n",
       "      <td>0.782776</td>\n",
       "      <td>1100</td>\n",
       "      <td>3</td>\n",
       "      <td>84645</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1625.0</td>\n",
       "      <td>123.52</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.54</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.1926</td>\n",
       "      <td>-0.6787</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "      <td>10</td>\n",
       "      <td>0.500080</td>\n",
       "      <td>1100</td>\n",
       "      <td>3</td>\n",
       "      <td>83607</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1527.0</td>\n",
       "      <td>127.76</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>2.89</td>\n",
       "      <td>-1.73</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.2521</td>\n",
       "      <td>0.7258</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>134</td>\n",
       "      <td>10</td>\n",
       "      <td>0.439874</td>\n",
       "      <td>1100</td>\n",
       "      <td>3</td>\n",
       "      <td>82642</td>\n",
       "      <td>7542.0</td>\n",
       "      <td>1730.0</td>\n",
       "      <td>132.94</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.29</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.2498</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>109</td>\n",
       "      <td>9</td>\n",
       "      <td>0.502749</td>\n",
       "      <td>2900</td>\n",
       "      <td>4</td>\n",
       "      <td>79124</td>\n",
       "      <td>89.0</td>\n",
       "      <td>491.0</td>\n",
       "      <td>122.72</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>6.11</td>\n",
       "      <td>-3.82</td>\n",
       "      <td>2.51</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>-0.5399</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 771 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   f1  f2        f3    f4  f5     f6      f7      f8      f9  ...  f770  \\\n",
       "0   1  126  10  0.686842  1100   3  13699  7201.0  4949.0  126.75  ...     5   \n",
       "1   2  121  10  0.782776  1100   3  84645   240.0  1625.0  123.52  ...     6   \n",
       "2   3  126  10  0.500080  1100   3  83607  1800.0  1527.0  127.76  ...    13   \n",
       "3   4  134  10  0.439874  1100   3  82642  7542.0  1730.0  132.94  ...     4   \n",
       "4   5  109   9  0.502749  2900   4  79124    89.0   491.0  122.72  ...    26   \n",
       "\n",
       "   f771  f772  f773    f774    f775  f776  f777  f778  loss  \n",
       "0  2.14 -1.54  1.18  0.1833  0.7873     1     0     5     0  \n",
       "1  0.54 -0.24  0.13  0.1926 -0.6787     1     0     5     0  \n",
       "2  2.89 -1.73  1.04  0.2521  0.7258     1     0     5     0  \n",
       "3  1.29 -0.89  0.66  0.2498  0.7119     1     0     5     0  \n",
       "4  6.11 -3.82  2.51  0.2282 -0.5399     0     0     5     0  \n",
       "\n",
       "[5 rows x 771 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 105471 entries, 0 to 105470\n",
      "Columns: 771 entries, id to loss\n",
      "dtypes: float64(653), int64(99), object(19)\n",
      "memory usage: 620.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f770</th>\n",
       "      <th>f771</th>\n",
       "      <th>f772</th>\n",
       "      <th>f773</th>\n",
       "      <th>f774</th>\n",
       "      <th>f775</th>\n",
       "      <th>f776</th>\n",
       "      <th>f777</th>\n",
       "      <th>f778</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105289.000000</td>\n",
       "      <td>105370.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>104407.000000</td>\n",
       "      <td>103946.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>52736.000000</td>\n",
       "      <td>134.603171</td>\n",
       "      <td>8.246883</td>\n",
       "      <td>0.499066</td>\n",
       "      <td>2678.488874</td>\n",
       "      <td>7.354533</td>\n",
       "      <td>47993.704317</td>\n",
       "      <td>2974.336018</td>\n",
       "      <td>2436.363718</td>\n",
       "      <td>134.555225</td>\n",
       "      <td>...</td>\n",
       "      <td>17.422543</td>\n",
       "      <td>5.800976</td>\n",
       "      <td>-4.246788</td>\n",
       "      <td>3.273059</td>\n",
       "      <td>0.233852</td>\n",
       "      <td>0.014797</td>\n",
       "      <td>0.310246</td>\n",
       "      <td>0.322847</td>\n",
       "      <td>175.951589</td>\n",
       "      <td>0.799585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>30446.999458</td>\n",
       "      <td>14.725467</td>\n",
       "      <td>1.691535</td>\n",
       "      <td>0.288752</td>\n",
       "      <td>1401.010943</td>\n",
       "      <td>5.151112</td>\n",
       "      <td>35677.136048</td>\n",
       "      <td>2546.551085</td>\n",
       "      <td>2262.950221</td>\n",
       "      <td>13.824682</td>\n",
       "      <td>...</td>\n",
       "      <td>18.548936</td>\n",
       "      <td>6.508555</td>\n",
       "      <td>4.828265</td>\n",
       "      <td>3.766746</td>\n",
       "      <td>0.073578</td>\n",
       "      <td>1.039439</td>\n",
       "      <td>0.462597</td>\n",
       "      <td>0.467567</td>\n",
       "      <td>298.294043</td>\n",
       "      <td>4.321120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>106.820000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-43.160000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-18.439600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26368.500000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.248950</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11255.000000</td>\n",
       "      <td>629.000000</td>\n",
       "      <td>746.000000</td>\n",
       "      <td>124.290000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.480000</td>\n",
       "      <td>-5.700000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.198400</td>\n",
       "      <td>-0.704275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>52736.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.498267</td>\n",
       "      <td>2200.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>76530.000000</td>\n",
       "      <td>2292.000000</td>\n",
       "      <td>1786.000000</td>\n",
       "      <td>128.460000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>3.570000</td>\n",
       "      <td>-2.600000</td>\n",
       "      <td>1.990000</td>\n",
       "      <td>0.251800</td>\n",
       "      <td>0.375400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>79103.500000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.749494</td>\n",
       "      <td>3700.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>80135.000000</td>\n",
       "      <td>4679.000000</td>\n",
       "      <td>3411.000000</td>\n",
       "      <td>149.080000</td>\n",
       "      <td>...</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>-1.010000</td>\n",
       "      <td>4.440000</td>\n",
       "      <td>0.283600</td>\n",
       "      <td>0.737100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>105471.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>7900.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>88565.000000</td>\n",
       "      <td>9968.000000</td>\n",
       "      <td>11541.000000</td>\n",
       "      <td>172.950000</td>\n",
       "      <td>...</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>58.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.040000</td>\n",
       "      <td>0.473700</td>\n",
       "      <td>11.092000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1212.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 752 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id             f1             f2             f3  \\\n",
       "count  105471.000000  105471.000000  105471.000000  105471.000000   \n",
       "mean    52736.000000     134.603171       8.246883       0.499066   \n",
       "std     30446.999458      14.725467       1.691535       0.288752   \n",
       "min         1.000000     103.000000       1.000000       0.000006   \n",
       "25%     26368.500000     124.000000       8.000000       0.248950   \n",
       "50%     52736.000000     129.000000       9.000000       0.498267   \n",
       "75%     79103.500000     148.000000       9.000000       0.749494   \n",
       "max    105471.000000     176.000000      11.000000       0.999994   \n",
       "\n",
       "                  f4             f5             f6             f7  \\\n",
       "count  105471.000000  105471.000000  105471.000000  105289.000000   \n",
       "mean     2678.488874       7.354533   47993.704317    2974.336018   \n",
       "std      1401.010943       5.151112   35677.136048    2546.551085   \n",
       "min      1100.000000       1.000000       0.000000       1.000000   \n",
       "25%      1500.000000       4.000000   11255.000000     629.000000   \n",
       "50%      2200.000000       4.000000   76530.000000    2292.000000   \n",
       "75%      3700.000000      10.000000   80135.000000    4679.000000   \n",
       "max      7900.000000      17.000000   88565.000000    9968.000000   \n",
       "\n",
       "                  f8             f9  ...           f770           f771  \\\n",
       "count  105370.000000  105471.000000  ...  105471.000000  105471.000000   \n",
       "mean     2436.363718     134.555225  ...      17.422543       5.800976   \n",
       "std      2262.950221      13.824682  ...      18.548936       6.508555   \n",
       "min         1.000000     106.820000  ...       2.000000       0.000000   \n",
       "25%       746.000000     124.290000  ...       5.000000       1.480000   \n",
       "50%      1786.000000     128.460000  ...      11.000000       3.570000   \n",
       "75%      3411.000000     149.080000  ...      23.000000       7.700000   \n",
       "max     11541.000000     172.950000  ...     168.000000      58.120000   \n",
       "\n",
       "                f772           f773           f774           f775  \\\n",
       "count  105471.000000  105471.000000  104407.000000  103946.000000   \n",
       "mean       -4.246788       3.273059       0.233852       0.014797   \n",
       "std         4.828265       3.766746       0.073578       1.039439   \n",
       "min       -43.160000       0.000000       0.000000     -18.439600   \n",
       "25%        -5.700000       0.740000       0.198400      -0.704275   \n",
       "50%        -2.600000       1.990000       0.251800       0.375400   \n",
       "75%        -1.010000       4.440000       0.283600       0.737100   \n",
       "max         0.000000      34.040000       0.473700      11.092000   \n",
       "\n",
       "                f776           f777           f778           loss  \n",
       "count  105471.000000  105471.000000  105471.000000  105471.000000  \n",
       "mean        0.310246       0.322847     175.951589       0.799585  \n",
       "std         0.462597       0.467567     298.294043       4.321120  \n",
       "min         0.000000       0.000000       2.000000       0.000000  \n",
       "25%         0.000000       0.000000      19.000000       0.000000  \n",
       "50%         0.000000       0.000000      40.000000       0.000000  \n",
       "75%         1.000000       1.000000     104.000000       0.000000  \n",
       "max         1.000000       1.000000    1212.000000     100.000000  \n",
       "\n",
       "[8 rows x 752 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f137</th>\n",
       "      <th>f138</th>\n",
       "      <th>f206</th>\n",
       "      <th>f207</th>\n",
       "      <th>f276</th>\n",
       "      <th>f277</th>\n",
       "      <th>f338</th>\n",
       "      <th>f390</th>\n",
       "      <th>f391</th>\n",
       "      <th>f419</th>\n",
       "      <th>f420</th>\n",
       "      <th>f469</th>\n",
       "      <th>f472</th>\n",
       "      <th>f534</th>\n",
       "      <th>f537</th>\n",
       "      <th>f626</th>\n",
       "      <th>f627</th>\n",
       "      <th>f695</th>\n",
       "      <th>f698</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8090000000000000</td>\n",
       "      <td>754485076006959972352</td>\n",
       "      <td>3200000000000</td>\n",
       "      <td>38600000000000000</td>\n",
       "      <td>7900000000000000</td>\n",
       "      <td>683091368180479950848</td>\n",
       "      <td>7610000000000</td>\n",
       "      <td>10370164393071999997033054208</td>\n",
       "      <td>13621142007705000132589703585884798976</td>\n",
       "      <td>137000000000</td>\n",
       "      <td>511000000000000</td>\n",
       "      <td>569877634360569973702656</td>\n",
       "      <td>3427303293502300223465356001280</td>\n",
       "      <td>240811094251680005357568</td>\n",
       "      <td>1185103615651699994464937312256</td>\n",
       "      <td>11724173453590999285553430528</td>\n",
       "      <td>16027029142402000396838501389877379072</td>\n",
       "      <td>8700000000000000000</td>\n",
       "      <td>8010000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2250000000000</td>\n",
       "      <td>15300000000000000</td>\n",
       "      <td>392000000000</td>\n",
       "      <td>1690000000000000</td>\n",
       "      <td>92300000000000</td>\n",
       "      <td>2140000000000000000</td>\n",
       "      <td>796594176</td>\n",
       "      <td>5098137566366599989877014528</td>\n",
       "      <td>5366154527659000357778647583412977664</td>\n",
       "      <td>9483264</td>\n",
       "      <td>1593188352</td>\n",
       "      <td>107000000000000000</td>\n",
       "      <td>9894337169928600158208</td>\n",
       "      <td>251470350285930004480</td>\n",
       "      <td>161196782629860003268263936</td>\n",
       "      <td>6391495663130699779035627520</td>\n",
       "      <td>7158933769610900052770065343332745216</td>\n",
       "      <td>5890000000000000000</td>\n",
       "      <td>5030000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>186000000000000</td>\n",
       "      <td>6910365323840000000</td>\n",
       "      <td>23700000000000</td>\n",
       "      <td>389000000000000000</td>\n",
       "      <td>10300000000000</td>\n",
       "      <td>69200000000000000</td>\n",
       "      <td>461000000000</td>\n",
       "      <td>26400269714792999161039945728</td>\n",
       "      <td>36117033568522998807722429270944907264</td>\n",
       "      <td>36051866452</td>\n",
       "      <td>63500000000000</td>\n",
       "      <td>313319151143610023936</td>\n",
       "      <td>222812827058929985669562368</td>\n",
       "      <td>116067852739909992448</td>\n",
       "      <td>61668865475731997253959680</td>\n",
       "      <td>36420952401170000260810932224</td>\n",
       "      <td>56027915541865997900093655676589441024</td>\n",
       "      <td>24512111987574001664</td>\n",
       "      <td>19855991371293999104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44500000000000000</td>\n",
       "      <td>11225194901267999096832</td>\n",
       "      <td>16098514954</td>\n",
       "      <td>35000000000000</td>\n",
       "      <td>22200000000000</td>\n",
       "      <td>295000000000000000</td>\n",
       "      <td>1330000000000</td>\n",
       "      <td>9333818143939599917454983168</td>\n",
       "      <td>12638526060843999893906772076814925824</td>\n",
       "      <td>5621900678</td>\n",
       "      <td>9380000000000</td>\n",
       "      <td>2641626213765599994052608</td>\n",
       "      <td>24452856014536001129152839155712</td>\n",
       "      <td>202899352692079984640</td>\n",
       "      <td>126293716597939998795235328</td>\n",
       "      <td>15267506423634001098621059072</td>\n",
       "      <td>24362045267421999852972382580757233664</td>\n",
       "      <td>9660000000000000000</td>\n",
       "      <td>6960000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52152926246</td>\n",
       "      <td>108000000000000</td>\n",
       "      <td>442000000000</td>\n",
       "      <td>1870000000000000</td>\n",
       "      <td>3630000000000</td>\n",
       "      <td>23100000000000000</td>\n",
       "      <td>2240000000000</td>\n",
       "      <td>196004669899870011305513451520</td>\n",
       "      <td>428213273484070002013091334592080642048</td>\n",
       "      <td>279000000000</td>\n",
       "      <td>659000000000000</td>\n",
       "      <td>68300000000000</td>\n",
       "      <td>922000000000000000</td>\n",
       "      <td>654000000000000000</td>\n",
       "      <td>89341826582645997305856</td>\n",
       "      <td>238204359524660008028924280832</td>\n",
       "      <td>550170020491249969340152709153269219328</td>\n",
       "      <td>108505460071560003584</td>\n",
       "      <td>94766610066210996224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                f137                     f138            f206  \\\n",
       "0   8090000000000000    754485076006959972352   3200000000000   \n",
       "1      2250000000000        15300000000000000    392000000000   \n",
       "2    186000000000000      6910365323840000000  23700000000000   \n",
       "3  44500000000000000  11225194901267999096832     16098514954   \n",
       "4        52152926246          108000000000000    442000000000   \n",
       "\n",
       "                 f207              f276                   f277           f338  \\\n",
       "0   38600000000000000  7900000000000000  683091368180479950848  7610000000000   \n",
       "1    1690000000000000    92300000000000    2140000000000000000      796594176   \n",
       "2  389000000000000000    10300000000000      69200000000000000   461000000000   \n",
       "3      35000000000000    22200000000000     295000000000000000  1330000000000   \n",
       "4    1870000000000000     3630000000000      23100000000000000  2240000000000   \n",
       "\n",
       "                             f390                                     f391  \\\n",
       "0   10370164393071999997033054208   13621142007705000132589703585884798976   \n",
       "1    5098137566366599989877014528    5366154527659000357778647583412977664   \n",
       "2   26400269714792999161039945728   36117033568522998807722429270944907264   \n",
       "3    9333818143939599917454983168   12638526060843999893906772076814925824   \n",
       "4  196004669899870011305513451520  428213273484070002013091334592080642048   \n",
       "\n",
       "           f419             f420                       f469  \\\n",
       "0  137000000000  511000000000000   569877634360569973702656   \n",
       "1       9483264       1593188352         107000000000000000   \n",
       "2   36051866452   63500000000000      313319151143610023936   \n",
       "3    5621900678    9380000000000  2641626213765599994052608   \n",
       "4  279000000000  659000000000000             68300000000000   \n",
       "\n",
       "                               f472                      f534  \\\n",
       "0   3427303293502300223465356001280  240811094251680005357568   \n",
       "1            9894337169928600158208     251470350285930004480   \n",
       "2       222812827058929985669562368     116067852739909992448   \n",
       "3  24452856014536001129152839155712     202899352692079984640   \n",
       "4                922000000000000000        654000000000000000   \n",
       "\n",
       "                              f537                            f626  \\\n",
       "0  1185103615651699994464937312256   11724173453590999285553430528   \n",
       "1      161196782629860003268263936    6391495663130699779035627520   \n",
       "2       61668865475731997253959680   36420952401170000260810932224   \n",
       "3      126293716597939998795235328   15267506423634001098621059072   \n",
       "4          89341826582645997305856  238204359524660008028924280832   \n",
       "\n",
       "                                      f627                   f695  \\\n",
       "0   16027029142402000396838501389877379072    8700000000000000000   \n",
       "1    7158933769610900052770065343332745216    5890000000000000000   \n",
       "2   56027915541865997900093655676589441024   24512111987574001664   \n",
       "3   24362045267421999852972382580757233664    9660000000000000000   \n",
       "4  550170020491249969340152709153269219328  108505460071560003584   \n",
       "\n",
       "                   f698  \n",
       "0   8010000000000000000  \n",
       "1   5030000000000000000  \n",
       "2  19855991371293999104  \n",
       "3   6960000000000000000  \n",
       "4  94766610066210996224  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_feats = data.dtypes[data.dtypes == 'object'].index\n",
    "data[categorical_feats].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "these categorical columns seems to be way too high and encoding them will be difficult, so we will drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['f137', 'f138', 'f206', 'f207', 'f276', 'f277', 'f338', 'f390', 'f391',\n",
       "       'f419', 'f420', 'f469', 'f472', 'f534', 'f537', 'f626', 'f627', 'f695',\n",
       "       'f698'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_feats:\n",
    "    data = data.drop([col], axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing value treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since some of the columns have missing values, so we will impute them by the mean of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         0\n",
       "f1         0\n",
       "f2         0\n",
       "f3         0\n",
       "f4         0\n",
       "        ... \n",
       "f775    1525\n",
       "f776       0\n",
       "f777       0\n",
       "f778       0\n",
       "loss       0\n",
       "Length: 752, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the mingging values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputing missing values with mean of that column\n",
    "data= data.fillna(data.mean(), inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id      0\n",
       "f1      0\n",
       "f2      0\n",
       "f3      0\n",
       "f4      0\n",
       "       ..\n",
       "f775    0\n",
       "f776    0\n",
       "f777    0\n",
       "f778    0\n",
       "loss    0\n",
       "Length: 752, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f612   -0.016543\n",
      "f776   -0.015506\n",
      "f315   -0.011110\n",
      "f314   -0.010643\n",
      "f70    -0.010450\n",
      "f323   -0.010394\n",
      "f69    -0.009851\n",
      "f631   -0.009097\n",
      "f734   -0.008987\n",
      "f322   -0.008834\n",
      "f738   -0.008340\n",
      "f1     -0.008231\n",
      "f428   -0.008081\n",
      "f10    -0.007784\n",
      "f666   -0.007747\n",
      "f290   -0.007706\n",
      "f299   -0.007622\n",
      "f665   -0.007568\n",
      "f291   -0.007263\n",
      "f775   -0.007223\n",
      "f298   -0.007095\n",
      "f526   -0.007027\n",
      "f740   -0.006850\n",
      "f285   -0.006798\n",
      "f667   -0.006711\n",
      "f211   -0.006582\n",
      "f425   -0.006499\n",
      "f426   -0.006379\n",
      "f9     -0.006301\n",
      "f699   -0.006135\n",
      "Name: loss, dtype: float64 \n",
      "\n",
      "f514    0.010524\n",
      "f370    0.010617\n",
      "f353    0.010761\n",
      "f617    0.011093\n",
      "f675    0.011158\n",
      "f13     0.011188\n",
      "f468    0.011211\n",
      "f556    0.011382\n",
      "f251    0.011880\n",
      "f221    0.012016\n",
      "f68     0.012987\n",
      "f597    0.013758\n",
      "f599    0.013758\n",
      "f670    0.014595\n",
      "f67     0.014740\n",
      "f674    0.019426\n",
      "f536    0.025652\n",
      "f471    0.039849\n",
      "loss    1.000000\n",
      "f33          NaN\n",
      "f34          NaN\n",
      "f35          NaN\n",
      "f37          NaN\n",
      "f38          NaN\n",
      "f678         NaN\n",
      "f700         NaN\n",
      "f701         NaN\n",
      "f702         NaN\n",
      "f736         NaN\n",
      "f764         NaN\n",
      "Name: loss, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Find all correlations of every feature with the target(loss)\n",
    "corr = data.corr()['loss'].sort_values()\n",
    "\n",
    "# Print the most negative correlations\n",
    "print(corr.head(30), '\\n')\n",
    "\n",
    "# Print the most positive correlations\n",
    "print(corr.tail(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f33', 'f34', 'f35', 'f37', 'f38', 'f678', 'f700', 'f701', 'f702', 'f736', 'f764']\n"
     ]
    }
   ],
   "source": [
    "# Remove variabels that have NaN correlation with loss  \n",
    "corr_tar_df = corr.to_frame().transpose()\n",
    "col_to_drop = corr_tar_df.columns[corr_tar_df.isna().any()].to_list()\n",
    "print(col_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= data.drop(columns = col_to_drop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To indicate whether a loan will be default or not, the loss was measured lies between 0 and 100. \n",
    "In these observation, a loss of 60 means that only 40 is reimbursed. If the loan did not default, the loss was 0.\n",
    "so, to transform this problem into binary classification, we will transform all non zero loss into class 1, \n",
    "which mean a default was triggered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     95688\n",
       "2      1297\n",
       "1      1145\n",
       "3      1086\n",
       "4      1038\n",
       "      ...  \n",
       "92        1\n",
       "77        1\n",
       "85        1\n",
       "80        1\n",
       "63        1\n",
       "Name: loss, Length: 89, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['loss'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    95688\n",
       "1     9783\n",
       "Name: loss, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the target into binary number: 0 for non-default and 1 for default\n",
    "#y_binary = y.copy()\n",
    "#y_binary[y_binary>0] = 1\n",
    "#y_binary.value_counts()\n",
    "data['loss'][data['loss']>0] = 1\n",
    "data['loss'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='loss', ylabel='count'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above count plot indicates that we have imbalanced dataset. This kind of dataset can influence many machine learning algorithms, leading some to ignore the minority class entirely. To overcome this situation resampling methods like oversampling or undersampling need to be done. This time, I will perform oversampling where we will duplicate or create new synthetic examples in the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95688 9783\n"
     ]
    }
   ],
   "source": [
    "# Divide by class\n",
    "count_class_0, count_class_1 = data['loss'].value_counts()\n",
    "print(count_class_0, count_class_1)\n",
    "data_class_0 = data[data['loss'] == 0]\n",
    "data_class_1 = data[data['loss'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random over-sampling:\n",
      "1    95688\n",
      "0    95688\n",
      "Name: loss, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='loss', ylabel='count'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# OVER SAMPLING \n",
    "data_class_1_over = data_class_1.sample(count_class_0, replace=True)\n",
    "data_test_over = pd.concat([data_class_0, data_class_1_over], axis=0)\n",
    "\n",
    "print('Random over-sampling:')\n",
    "print(data_test_over.loss.value_counts())\n",
    "\n",
    "sns.countplot(data_test_over['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(191376, 741)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test_over.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(191376, 739)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data_test_over.drop(['id', 'loss'],  axis = 1)\n",
    "y = data_test_over['loss']\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(153100, 739), (38276, 739), (153100,), (38276,)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sp\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "[X_train.shape, X_test.shape, y_train.shape, y_test.shape]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time, machine learning algorithms perform better when datasets are scaled to a standard range,\n",
    "especially, the data has input values with differing scales. \n",
    "The main idea of standardization is  rescaling the distribution of values so that the mean \n",
    "of observed values is 0 and the standard deviation is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardization of Variables\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scalar= StandardScaler()\n",
    "X_train = scalar.fit_transform(X_train)\n",
    "X_test = scalar.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimentional Reduction with Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA, is a dimensionality-reduction method that is often used to reduce the dimensionality of data sets, \n",
    "by transforming a large set of variables into a smaller one that still retain as much information as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEECAYAAADAoTRlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAAAsTAAALEwEAmpwYAAAsQUlEQVR4nO3deVxU5eIG8GdmYEZgQFlEIYUQRcn0EmrmTcslc8tKs9TUFvWWXZe66nXNVNzraqa/VistbTHLa7fsXtdS0dxFRVFcSEEFZGcGmO28vz+QUQQ8SLPBPN/Pxw+znnlmjMe3d855j0IIIUBERG5F6ewARETkeCx/IiI3xPInInJDLH8iIjfE8icickMezg5QHQkJCdBoNDV6rsFgqPFzHak25GRG26gNGYHakZMZ5V87Jiam0vtqRflrNBpER0fX6LlJSUk1fq4j1YaczGgbtSEjUDtyMqP8a1eF0z5ERG6I5U9E5IZY/kREbojlT0Tkhlj+RERuiOVPROSG7Fb+x48fx4gRIyrcvnPnTjzzzDMYPHgwvvvuO3u9PBER3YFd9vNftWoV/vOf/8DLy6vc7SaTCYsWLcL3338PLy8vDB06FN27d0dQUJA9YhBZmS0STBYBo1mC0VL6x1R22SzBLAlYJAFJ3PgpCViEgLnssvU+wCJu3ma9fOOnJAAhBAQAIYCy9dJvXTk9PSMPwdcv3Lj91scAAgK3LrJe9rzKHnf77baWlZWDoLRkO239T7jlA7qelYOGqWedGEben8mo8VRhWMcwNPBW2ziVnco/LCwMK1euxJQpU8rdfuHCBYSFhaF+/foAgHbt2uHQoUPo06fPHbdnMBjueLDCnZSUlNT4uY5UG3LaO6PJIqA3StAZLdAZJeufIqOEErOEErOAwSxuuVz6s8QswWARpZdNFpilSzBLpdszSTcK3OXOWpHj7ADVlOfsAJVSlLuW55wQdyWvRs9SqxQIVRWiVcN6to0DO5V/r169kJaWVuF2nU4HX19f63UfHx/odDrZ7fEIX9dwNxmFECgoNiNLb0BWoQHZeiOydQZc15X+zNIZkKM3Ir/YhPxiEwqKzSg2WWS3q1YpUc9TCW+1B7zVKtTz9IC3RgU/tQpenioYi/VoGNAAag8lPFVKaG78VN/yU61SlP4su02lhIdKAaVCAZVSAZVCAaWy9HLZbR63XFYpYb1887bSy0pF6X0AoFAACiisTaW4cfHs2WS0atXSWmDWx924XO4nFLdcBhRl2y732PJVaCt17b9JZ3HVI3wduryDVquFXq+3Xtfr9eX+MaDaw2SRkJpThMs5RbiaV4Jr+cW4kleMa3kluJpfjGv5JTCapQrPUygAf281grRqBPio0SxICz8vD9T38oRfPU/U9/a0Xvbz8kR9Lw/41vOE941y91Dd+Wuq2lAGPmoltJpasbIK1WEO/S8wMjISly5dQl5eHry9vXH48GGMGjXKkRHoLuUXm3DmWgHOX9fhyNls5B04hJQsPS7nFMFyy1yKUgE09quHkAZeaNukAXq3roeGvhoEaUv/BGrVCNJq4O/tKVvgRGR/Din/n376CUVFRRg8eDCmTZuGUaNGQQiBZ555Bo0aNXJEBJIhhMCVvGKcTMtH0rUCnL5WiKRrBbiSV2x9jEalQERDLaJDfNG3TWNEBGkRHuiNexp4IdhXw1InqkXsVv5NmjSx7srZv39/6+3du3dH9+7d7fWyVE0lJgsSr+Tj6OVcHL2Uh6OXc5FZaABQOopv1lCL2HB/DHsoDNEhfohq5Iu8qylofd99Tk5ORLbAiUc3YZEETl7Jx97zWdh7PguHL+Va5+TDArzRKTIQsWH++EvTBmjZyBdealWFbRRcs88Xi0TkeCz/OqzEZMGec1n4b+I17EjKRH6xCQAQHeKHFx4Kx4MRAXggzB8NfV37ZBhEZHss/zrGIgnsPncdG49ewc6kDOiNFtT38kSP6GB0axmMv0YGIlDLsidydyz/OiIlS48Nh1Pxw9E0ZBQY4O/tiSdj7kGf+xujU2QgPPllLBHdguVfiwkhsOdcFj6NT8Hu5OtQKoCuLYMx98km6N6qEdQeLHwiqhzLvxYymC348dhVfBp/EckZOjT01WBSzyg816EpGvnZ/jBwIqp7WP61iMFswXeH0/DBr+dxLb8E0SF+WPrsX/DEX0Kg8ai4dw4RUVVY/rWA2SJhw5E0rNxxDlfzS9Au3B9vD2qLzs2D7LauCxHVbSx/F7cr+ToWbk7C2YxCxIY1wBKWPhHZAMvfRZ3P1GHez6exK/k6wgK88eGwWPS+vzFLn4hsguXvYkpMFnzw63l8uOsC6nmq8Ga/aIzoFM45fSKyKZa/C9l7PgtvbkpESpYeT8eEYma/+3j0LRHZBcvfBegNZqz8/Tp+Sb6IewO9sW5UR3RuwVNbEpH9sPyd7PAfOZj43XGk5hTh1Uea4R89o1DPk1M8RGRfLH8nMVskLNuWjI92XcA9/l54u3cInu3q2megIqK6g+XvBBkFJRj/9TEc/CMHg9s3xaz+9yH14jlnxyIiN8Lyd7B957Mw4dtj0BssWD44Bk8/cI+zIxGRG2L5O4gQAh/tuoh3tpxBs4ZafPO3WLRoxJPXE5FzsPwdwGC2YPrGk9h49AqeaBuCJc+0hY+GHz0ROQ8byM6ydQaMWXcEh/7IxT8ei8KEHs15lC4ROR3L345Sc4ow/LMDSM8vwcqhD6D/X0KdHYmICADL327OZ+ow/NMDKDKa8fXfHkK7cH9nRyIismL520HilXy88PlBKBUKrH+1E6JD/JwdiYioHJa/jZ1JL8CwTw9Aq/HAutEdERHk4+xIREQVsPxtKCVLj+GfHoSXpwrfvvIQmgZ4OzsSEVGleIZvG7mSV4zhnx6AJATWje7I4icil8byt4H8YhNe/PwgCkpM+HLkg2gerHV2JCKiO6p2+efl5dkxRu1lskgY9/VR/JGlxycj2uP+e+o7OxIRkSzZOf+DBw8iLi4OFosFvXv3RmhoKJ599llHZHN5QgjM/s8p7DmXhbcHtUWnyEBnRyIiqhbZkf97772HdevWISgoCGPGjME333zjiFy1wneHU/H1gct4rWsknmvf1NlxiIiqTbb8lUolGjRoAIVCAY1GAx8f7roIlO7S+daPp9C5eRAmP97S2XGIiO6KbPmHhYVh6dKlyMvLwyeffILQUC5RUGQ0Y+xXR+Hn5Yl3B8dApeRaPURUu8iW/9y5cxEaGop27drB29sb8+bNc0Qul7bkv2dw4boe7w2O4QnWiahWki3/U6dOwWQyYfbs2Th27BjOnz/viFwua9/5LHzx+yW8/PC9+GtznmSdiGon2fKPi4tD165dAQBvvPEGFixYYO9MLquwxIR/fn8CEUE+mNKrlbPjEBHVmOyunp6enggLCwMANG3aFEql+x4Xtvi/Z3AtvxgbxnSCl1rl7DhERDUmW/6hoaFYtmwZYmJicOLECQQHBzsil8s5ejkXXx24jJEPR6BdeICz4xAR/Smyw/hFixYhICAAu3btQmBgIBYtWuSIXC7FbJEw89+JaOxXDxMfj3J2HCKiP0125K9WqxEbG4vWrVsDAI4fP44OHTrYPZgrWbPvDyRdK8CHw2Kh5bl3iagOkG2y8ePHIycnByEhIRBCQKFQyJa/JEmYM2cOzp49C7Vajfnz5yM8PNx6/+eff46ff/4ZCoUCY8aMQc+ePf/8O7GTzIISvLstGd1aNkTv+xs7Ow4RkU3Iln9WVha+/fbbu9ro9u3bYTQasX79eiQkJGDx4sX48MMPAQAFBQX48ssvsXXrVhQXF+Ppp5926fJfti0ZRouEOU+25onXiajOkJ3zj4iIQEZGxl1t9MiRI+jSpQsAICYmBomJidb7vLy8EBoaiuLiYhQXF7t0oSZnFOK7w6kY/lA4wgO5rAUR1R2yI/+jR4+iW7duCAi4uYdLfHz8HZ+j0+mg1d5c016lUsFsNsPDo/TlQkJC0K9fP1gsFrz66quyIQ0GA5KSkmQfV5mSkpIaP3fOjnR4eSjRu4mo8Taq68/kdBRmtI3akBGoHTmZseZky3/Lli13vVGtVgu9Xm+9LkmStfh3796NzMxM7NixAwAwatQoxMbGom3btlVuT6PRIDo6+q5zAEBSUlKNnpt4JR8H0i5iUs8odHygRY1e+27UNKcjMaNt1IaMQO3IyYzyr10V2fJPSEjAxo0bYTKZAACZmZn47LPP7vic2NhY/Prrr+jbty8SEhIQFXVz98j69eujXr16UKvVUCgU8PX1RUFBQXXfi8O8/+t5+NbzwIsP3+vsKERENidb/nPmzMHo0aOxZcsWREVFwWg0ym60Z8+e2Lt3L4YMGQIhBBYuXIjVq1cjLCwMPXr0wL59+/Dcc89BqVQiNjYWDz/8sE3ejK0kZxTiv4npGN+9OfzqeTo7DhGRzcmWv7+/P5544gns3bsX48ePx/Dhw2U3qlQqERcXV+62yMhI6+UJEyZgwoQJNYjrGB/8eh7eahVefjjC2VGIiOyiWidzOXfuHIqLi3Hx4kXk5+c7IpfTXMsvxk8nrmHog2EI8FE7Ow4RkV3Ilv+0adNw7tw5jBgxApMnT8YzzzzjiFxO89X+y5CEwEt/vdfZUYiI7KbKaZ+yXTPDw8OtR+fe7cFetU2JyYKvD17GY9GN0DTA29lxiIjspsrynzp1KpYuXYrevXtXOBCrbDfNuubnE9eQozfiZY76iaiOq7L8ly5dCgB4/fXX8dRTTzkskDN9dygVzYJ80Cky0NlRiIjsSnbOf8OGDY7I4XSXs4tw8I8cPNOuiUsvOUFEZAuyu3oajUY8/fTTiIiIsJ7Fq+z/CuqSjcfSoFAAAx64x9lRiIjsTrb8J0+e7IgcTiWEwMajV/DXyECENvBydhwiIruTnfaJiopCZmYmrl69iitXruDYsWOOyOVQCal5uJxThIEPNHF2FCIih5Ad+Y8bNw7NmjVDcnIyNBoNvLzq3sh42+kMqJQKPBbdyNlRiIgcQnbkL4RAXFwcIiIisHr1auTl5TkglmNtO52BjhEBqO/NdXyIyD3Ilr9KpYLBYLCeeMVisTgil8NczSvGuUwdurcKdnYUIiKHkS3/YcOGYc2aNXj44Yfx6KOPokmTujUvvvd8FgCgc4sgJychInIc2Tn/8PBw9OrVCwDQp0+fcmfoqgv2ns9CkFaNlo18nR2FiMhhZMt/+fLlyMvLw8CBA/HEE084IpPDCCGw90I2/hoZxAO7iMityE77fPTRR1i5ciUKCgowcuRIzJw50xG5HOJcpg7XCw14uDmXcyAi9yJb/kDpCp9GoxGSJEGlUtk7k8OUzfc/3Jzz/UTkXmSnfV544QUYjUYMGjQIa9asgbd33VnqeO/5LIQHeqOJf915T0RE1SFb/jNnzkTLli0dkcWhzBYJBy7moH9MqLOjEBE5nOy0T10sfgA4k16IQoMZHSMCnB2FiMjhqjXnXxcdu5wLAIgN83dyEiIix3Pb8j9yKRfBvho08a97axUREcmpcs6/c+fOAACTyYTi4mKEhIQgPT0dgYGB2Llzp8MC2svRy3loF+7P/fuJyC1VOfKPj49HfHw8unTpgi1btmDLli3YunUr2rZt68h8dnG90IDLOUWc8iEityU77ZOWloaQkBAAQKNGjXDt2jW7h7K346l5AIAHwho4NQcRkbPI7uoZGRmJf/7zn2jbti2OHTuG1q1bOyKXXSVdKwAAtArxc3ISIiLnkC3/efPmYdu2bbh06RL69euHHj16OCKXXZ1JL0R4oDe0Gtm3T0RUJ8lO+xQVFeH06dNISUmBxWLBpUuXHJHLrpLSC9CqMVfxJCL3JVv+M2bMQNOmTXHp0iUEBQXV+oXdio0W/JGlR6vGnPIhIvclW/55eXkYNGgQPDw8EBsbC0mSHJHLbpIzCiEJIJrz/UTkxqp1kNeFCxcAAOnp6bV+Vc8z6aVf9kaHcNqHiNyXbPm/+eabmDFjBk6fPo0JEyZg2rRpjshlN0nXCuGjVqEpV/IkIjcmu7tLVFQU1q9f74gsDpF0rQAtG/tCqeSRvUTkvmTLf9OmTfjkk09gMBist+3YscOuoewpOaMQve8PcXYMIiKnki3/VatW4cMPP7Qe5Vub5ReZkFtkQrMgH2dHISJyKtnyb9q0KcLDwx2Rxe4u5egBAGGBnO8nIvcmW/716tXD6NGjER0dbV0Bc+LEiXYPZg9/ZBcBAO4N5MifiNybbPk/+uijjsjhEJezb4z8AzjyJyL3VmX5nzx5Em3atEHDhg0dmceuLmUXIdhXAy917T5WgYjoz6qy/H///Xe0adMGmzdvrnBf2YleapvLOUUc9RMR4Q7l/8orrwAAFi1aVO72zMxM2Y1KkoQ5c+bg7NmzUKvVmD9/frkvjXft2oX3338fQgi0bt0as2fPdsgZtdILStC2SQO7vw4RkauTPcL3vffew0MPPYR27dqhdevWePnll2U3un37dhiNRqxfvx6TJk3C4sWLrffpdDq88847+Oijj7Bhwwbcc889yM3N/XPvohqEEEjPL0FjP43dX4uIyNXJlv/OnTuxe/du9O/fH7/88gsaNWoku9EjR46gS5cuAICYmBgkJiZa7zt27BiioqKwZMkSPP/88wgKCkJAQMCfeAvVk19sgsEsoZFfPbu/FhGRq5Pd26dhw4ZQq9XQ6/UIDw+HyWSS3ahOp4NWq7VeV6lUMJvN8PDwQG5uLg4cOIBNmzbB29sbw4YNQ0xMDCIiIqrcnsFgQFJSUjXfUnklJSVISkpCSq4RAGDRZSMpySDzLMcry+nKmNE2akNGoHbkZMaaky3/xo0b4/vvv4eXlxeWLl2KgoIC2Y1qtVro9XrrdUmS4OFR+lINGjQotxdR+/btkZSUdMfy12g0iI6Oln3dyiQlJSE6OhoZZzMBpKH9fZGIDrf//2ncrbKcrowZbaM2ZARqR05mlH/tqshO+8TFxaFTp06YMmUKgoODsWzZMtkXjI2Nxe7duwEACQkJiIqKst7XunVrJCcnIycnB2azGcePH0fz5s2r8z7+lIyCEgDgtA8REe4w8q9sJU+1Wo3Dhw8jMjLyjhvt2bMn9u7diyFDhkAIgYULF2L16tUICwtDjx49MGnSJIwePRoA0Lt373L/ONhLen7pVE+wL8ufiKjK8r9+/XqNN6pUKhEXF1futlv/wejXrx/69etX4+3XRGZhCQJ81FB7VOv8NUREdVqV5T9u3DgApbtIbt++HSkpKWjRogW6devmsHC2lK0zItBH7ewYREQuoVpn8vrll1+g0WiwadOmCgd91RY5eiMCWP5ERACqsbdPcnIyNmzYAAB48cUX8dxzz9k9lD1k6Q1o1Zjn7SUiAqox8g8LC0NqaioAIDs7u9ae1CVHb0SgD4/uJSICqjHyT0hIQN++fREaGor09HSo1Wrrwm7x8fF2D2gLZouEvCITp32IiG6QLf+tW7dCpbq5BPLtR+/WBrlFpUclB2pZ/kREQDWmfV588UXrSp4nTpzAkCFD7B7K1rL1pfv4c+RPRFRKduQ/duxYvPLKK+jQoQMSExPx3nvvOSKXTeXoStf1YfkTEZWSHfm3aNECgYGB2LdvH9q2bYuwsDBH5LKpbH1p+fMLXyKiUrLlP2zYMAwdOhSbN29GcHAwBg8e7IhcNpVXVFr+/t6eTk5CROQaZKd9vvjiCzRu3BgAMGrUKHTs2NHuoWxNZ7AAALT1ZN8uEZFbkG3DwsJCTJw4EQUFBXjyySfRokULR+SyKb3BDKUC8PLkiduJiIBqTPvMnz8fixYtgr+/PwYNGoSVK1c6IpdN6Qxm+Gg8HHKeYCKi2qBaS1yGh4dDoVAgICAAPj4+9s5kc3qDGVoNp3yIiMrIln/9+vXx7bffori4GJs3b4afn58jctmU3lg68iciolKy5b9w4UKkpaXB398fiYmJWLBggSNy2VRhCUf+RES3km1ErVaLyZMnOyKL3XDah4ioPLc4rVWR0QIvNff0ISIq4xblbzRLqMfdPImIrGTnQnQ6HVatWoXMzEx069YNLVu2RHh4uCOy2YzBLEHDc/cSEVnJNuKMGTPQtGlTXLp0CUFBQZg5c6YjctmUwWxh+RMR3UK2EfPy8jBo0CB4eHggNjYWkiQ5IpdNlY78Oe1DRFSmWsPhCxcuAADS09PLndiltjCYJag58icispJtxDfffBMzZszA6dOnMWHCBEybNs0RuWxGCAEj5/yJiMqR/cL38uXL+Oabb6BU1s7yNEkCAKDxrJ35iYjsQbYRf//9dzz11FN49913kZqa6ohMNmW03Ch/zvkTEVnJjvxnzZoFo9GIHTt2IC4uDiaTCWvWrHFANNu4Wf4c+RMRlalWI544cQLx8fHIzs5Gp06d7J3JpkwsfyKiCmRH/n379kWrVq3w7LPP1spF3awjfx7hS0RkJVv+X331Ffz9/R2RxS7Kyl+t4sifiKhMleU/YcIErFixAv37969wX3x8vF1D2RLn/ImIKqqy/FesWAEA2LBhA0JCQqy3lx3wVVtwzp+IqKIqyz85ORkZGRn417/+hSlTpkAIAUmSsHTpUvz444+OzPinmG/s5+/J8icisqqy/AsKCvDLL78gOzsbP//8MwBAoVDg+eefd1g4WzBxzp+IqIIqy799+/Zo3749Tp06hdatWzsyk02Zb6xD58nyJyKykt3bJz09HcuWLYPJZIIQAnl5efjpp58ckc0mrCN/TvsQEVnJNuLy5csxbtw4hISEYMCAAWjZsqUjctlM2do+nPYhIrpJthGDg4PxwAMPAAAGDhyIjIwMu4eyJWv5c+RPRGQl24ienp44dOgQzGYz9uzZg9zcXEfkshnzjWkfT5XCyUmIiFyHbPnPnTsXZrMZr732Gr777ju89tprjshlMxz5ExFVVOUXvikpKdbLjRs3BgBMnDixWhuVJAlz5szB2bNnoVarMX/+/AonfZckCa+88gp69OiBoUOH1iR7tZhZ/kREFVRZ/m+99ValtysUCnz55Zd33Oj27dthNBqxfv16JCQkYPHixfjwww/LPWb58uUoKCioQeS7U7a3j2ctPRkNEZE9VFn+a9eurfFGjxw5gi5dugAAYmJikJiYWO7+//3vf1AoFNbHyDEYDEhKSqpRlhKjGR5K4OzZMzV6vqOUlJTU+D06CjPaRm3ICNSOnMxYc7L7+Xfv3h0Kxc0vS319fbFp06Y7Pken00Gr1Vqvq1QqmM1meHh4IDk5GT///DNWrFiB999/v1ohNRoNoqOjq/XY24lD2VB7qGr8fEdJSkpiRhtgRtupDTmZUf61qyJb/v/73/8AlJ4IPTEx0Xr9TrRaLfR6vfW6JEnw8Ch9qU2bNiEjIwMvvvgirly5Ak9PT9xzzz145JFHZLdbEyZJcL6fiOg2suWvVqutl9u1a4dly5bJbjQ2Nha//vor+vbti4SEBERFRVnvmzJlivXyypUrERQUZLfiB0rn/Lm0AxFRebLlv3TpUuu0T2ZmJpTV+OK0Z8+e2Lt3L4YMGQIhBBYuXIjVq1cjLCwMPXr0+POp74JZEjy6l4joNrLl36xZM+vlVq1aVetLWqVSibi4uHK3RUZGVnjc+PHjq5PxTzFZOO1DRHQ72VZ87LHH4OfnB41GAwDYs2eP3UPZEkf+REQVyY78R44ciebNm8PX1xdA6X7+ffv2tXswWzFJgKcHl3YgIrqVbPn7+vpi0aJFjshiFyaLgNqTI38iolvJln/nzp3xzTffoHnz5tbbOnToYNdQtmSSBHw47UNEVI5s+R8+fBhGoxGHDh0CUDrtU6vKn1/4EhFVIFv+RUVFWLNmjQOi2Ae/8CUiqki2/Fu0aIHNmzcjOjraur9/RESE3YPZCkf+REQVyZb/mTNncObMzUXRqrOqpysxSzzCl4jodrLl/2dW93QFXNuHiKgiu6zq6UrMFnDkT0R0G7us6ulKTJKAhiN/IqJyZFtRrVZDrVZDo9GgXbt2OH36tCNy2YxJEjx5OxHRbeyyqqcr4d4+REQV2WVVT1dhkQQkwTl/IqLbybZiREQECgsLMWDAAOzYsQOpqamOyGUTJosEABz5ExHdRrYV582bh65duwIA3njjDSxYsMDemWymrPw9a9lUFRGRvcm2oqenJ8LCwgAATZs2rVVz/lJp90Op5Be+RES3kp3zDw0NxbJlyxATE4MTJ04gODjYEblswiIEAIA7+xARlSc7jF+0aBECAgKwa9cuBAQE1Kq1/S3SjfLnyJ+IqBzZkb9Go8FLL73kgCi2J90Y+XPah4iovNozgV8D1pG/guVPRHQrtyh/jvyJiMqr0+UvCY78iYgqU6fL33xj5O/B3X2IiMqp0+UvlU37cORPRFROnS5/637+nPMnIiqnbpc/R/5ERJWq0+VftrwDR/5EROXV6fK/Oe3j5CBERC6mTtcip32IiCpXp8tf4he+RESVqtPlb7aw/ImIKlOny59H+BIRVa5Olz+XdCYiqlzdLn8u6UxEVKk6Xf4Sl3QmIqpUnS5/TvsQEVWuTpe/9UxeHPkTEZVTp8vfwuUdiIgqVafL33xjcR+WPxFRebIncK8JSZIwZ84cnD17Fmq1GvPnz0d4eLj1/jVr1mDz5s0AgEcffRTjxo2zRwwe4UtEVAW7jPy3b98Oo9GI9evXY9KkSVi8eLH1vtTUVPznP//Bt99+i++++w7x8fE4c+aMPWLcnPbhnD8RUTl2GfkfOXIEXbp0AQDExMQgMTHRel/jxo3x6aefQqVSAQDMZjM0Gs0dt2cwGJCUlHTXOdKuFAAALl48D32m510/35FKSkpq9B4diRltozZkBGpHTmasObuUv06ng1artV5XqVQwm83w8PCAp6cnAgICIITA22+/jfvuuw8RERF33J5Go0F0dPRd50govAwgCy2jWiCkvtddP9+RkpKSavQeHYkZbaM2ZARqR05mlH/tqthl2ker1UKv11uvS5IED4+b/84YDAZMnjwZer0es2fPtkcEALfs589pHyKicuxS/rGxsdi9ezcAICEhAVFRUdb7hBD4+9//jpYtWyIuLs46/WMPEpd3ICKqlF2mfXr27Im9e/diyJAhEEJg4cKFWL16NcLCwiBJEg4ePAij0Yg9e/YAACZOnIgHHnjA5jk48iciqpxdyl+pVCIuLq7cbZGRkdbLJ0+etMfLVmAtfxXLn4joVnX6IC+u509EVDm7jPxdxeP3NcbV9Az4aOr02yQiumt1euR/b5APBrfxd3YMIiKXU6fLn4iIKsfyJyJyQyx/IiI3xPInInJDLH8iIjfE8icickMsfyIiN8TyJyJyQwohbqyB4MISEhJkT/hCRETlGQwGxMTEVHpfrSh/IiKyLU77EBG5IZY/EZEbYvkTEbkhlj8RkRti+RMRuSGWPxGRG6qzp7iSJAlz5szB2bNnoVarMX/+fISHhzs10/Hjx/Gvf/0La9euxaVLlzBt2jQoFAq0aNECs2fPhlKpxP/93//ht99+g4eHB2bMmIG2bds6LJ/JZMKMGTNw5coVGI1GvPbaa2jevLlL5bRYLHjzzTeRkpIChUKBuXPnQqPRuFTGMtnZ2Rg4cCA+//xzeHh4uGTGAQMGQKvVAgCaNGmCwYMHY8GCBVCpVOjcuTPGjRvn9N+ljz/+GDt37oTJZMLQoUPx4IMPutRnuXHjRvz73/8GULpffVJSEtauXetyn2MFoo7asmWLmDp1qhBCiGPHjokxY8Y4Nc8nn3winnjiCfHss88KIYR49dVXxf79+4UQQsyaNUts3bpVJCYmihEjRghJksSVK1fEwIEDHZrx+++/F/PnzxdCCJGbmyseffRRl8u5bds2MW3aNCGEEPv37xdjxoxxuYxCCGE0GsXf//538fjjj4vz58+7ZMaSkhLx1FNPlbvtySefFJcuXRKSJInRo0eLU6dOOfV3af/+/eLVV18VFotF6HQ6sWLFCpf8LMvMmTNHfPvtty73OVamzk77HDlyBF26dAEAxMTEIDEx0al5wsLCsHLlSuv1U6dO4cEHHwQAPPLII9i3bx+OHDmCzp07Q6FQIDQ0FBaLBTk5OQ7L2Lt3b7z++usAACEEVCqVy+V87LHHMG/ePADA1atX4efn53IZAWDJkiUYMmQIgoODAbjm3/eZM2dQXFyMkSNH4oUXXsChQ4dgNBoRFhYGhUKBzp07W3M663cpPj4eUVFRGDt2LMaMGYOuXbu65GcJACdPnsT58+fRr18/l/scK1Nny1+n01n/dxYAVCoVzGaz0/L06tULHh43Z9mEEFAoFAAAHx8fFBYWVshcdruj+Pj4QKvVQqfTYcKECXjjjTdcMqeHhwemTp2KefPmoX///i6XcePGjQgICLD+ogOu+fddr149jBo1Cp999hnmzp2L6dOnw8vLq0IeZ/4u5ebmIjExEe+99x7mzp2LyZMnu+RnCZROT40dO7bKLK7WSXV2zl+r1UKv11uvS5JUrnydTam8+e+uXq+Hn59fhcx6vR6+vr4OzXXt2jWMHTsWzz//PPr374933nnHJXMuWbIEkydPxnPPPQeDweBSGX/44QcoFAr8/vvvSEpKwtSpU8uNQl0hIwBEREQgPDwcCoUCERER8PX1RV5eXoWcJSUlTvtdatCgAZo1awa1Wo1mzZpBo9EgPT29QkZnf5YFBQVISUnBQw89BJ1OVyGLsz/HytTZkX9sbCx2794NoHRhuKioKCcnKu++++7DgQMHAAC7d+9G+/btERsbi/j4eEiShKtXr0KSJAQEBDgsU1ZWFkaOHIl//vOfGDRokEvm3LRpEz7++GMAgJeXFxQKBe6//36XyvjVV19h3bp1WLt2LaKjo7FkyRI88sgjLpURAL7//nssXrwYAJCRkYHi4mJ4e3vj8uXLEEIgPj7emtNZv0vt2rXDnj17IISwZuzUqZPLfZaHDh1Cp06dAJQOPD09PV3qc6yM6wyFbaxnz57Yu3cvhgwZAiEEFi5c6OxI5UydOhWzZs3CsmXL0KxZM/Tq1QsqlQrt27fH4MGDIUkS3nrrLYdm+uijj1BQUIAPPvgAH3zwAQBg5syZmD9/vsvkfPzxxzF9+nQMGzYMZrMZM2bMQGRkpMt9lrdzxb/vQYMGYfr06Rg6dCgUCgUWLlwIpVKJyZMnw2KxoHPnzvjLX/6CNm3aOO13qVu3bjh06BAGDRoEIQTeeustNGnSxOU+y5SUFDRp0sR6vWyKylU+x8pwVU8iIjdUZ6d9iIioaix/IiI3xPInInJDLH8iIjfE8icickMsf6r1RowYgQsXLthl2+vWrUOfPn3wyy+/2GX7jpaXl4effvrJ2THIBbD8ie5g69atWL58Ofr27evsKDZx9uxZ7Ny509kxyAXU2YO8yHVt3LgRu3btQklJCS5fvoy//e1vGDhwIEaMGIE5c+YgMjIS33zzDbKysjBgwAD84x//QEhICNLS0tCvXz+cO3cOp0+fRteuXTFx4kQAwIoVK5Cbmwu1Wo23334bAQEBWLp0KQ4fPgxJkvDSSy+hT58+GDFiBAICApCfn4/PPvsMKpUKAJCWloYZM2bAYrFAoVDgzTffxPHjx3H69GnMnDkT7777Lpo2bQoAKCkpwfTp03H16lWYTCbMmjUL999/P6ZPn460tDRYLBa8/PLL6Nu3L0aMGIGWLVvi3Llz8Pb2Rvv27REfH4+CggJ8/vnn2LFjB7Zv3w69Xo/c3FyMHTsWvXr1wt69e7F8+XJoNBo0aNAACxcuRFJSElatWgVPT0+kpaWhb9++eO2113Dt2jXMmjULBoMBGo0G8+bNg8ViwaRJk9C4cWOkpqaiTZs2mDt3Lj766COcOXMG69evh7+/P1atWgUPDw8EBwfj3XffLbfsCNVxTlhJlNzcDz/8IEaOHCmEECIlJUX06tVLCCHE8OHDxfnz54UQQnz99ddixYoVIjU1VXTs2FEUFBSIzMxM0aZNG5GbmytKSkpEp06drM/7+eefhRBCrFu3TixcuFD89ttv4o033hBClC5d/OSTT4r8/HwxfPhwsXXr1gqZxo8fL7Zt2yaEEOL06dNiwIABFTKVWb16tXjnnXes+VevXi3Wrl0rFixYIIQQorCwUPTs2VNkZ2eL4cOHix9//FEIIcTIkSPFunXrhBBCTJkyRWzbtk388MMP4qWXXhIWi0Vcv35ddO3aVRiNRtGtWzeRnp4uhBBizZo1YvHixWL//v2iT58+wmQyCb1eL2JjY4UQQrz++uvit99+E0IIsW/fPjFx4kSRmpoqHnzwQVFYWCjMZrPo2rWryMzMFPv377d+LuPHjxf//e9/hRBC/Pvf/xb5+fk1+vuk2on/zJNTtGrVCgAQEhICo9FY4X5xy4HnTZs2ha+vL/z8/BAUFIQGDRpAo9FYV3YEgPbt2wMoXdMpJSUFycnJOHXqFEaMGIHRo0fDbDbjypUrAEoXNLvdhQsX0KFDBwBAdHR0ucXDbnfx4kXExMQAAO6991689NJL5Z6v1WoRGRmJ1NRUAEDr1q0BAH5+fmjevLn1ctmCdB06dIBSqURQUBD8/PyQlZUFrVaLRo0aWe8/d+4cACAqKgoeHh7w9vZGvXr1AADJycn4+OOPMWLECLz//vvIzs4GULqMuFarhUqlQsOGDcstgAcA06dPx/79+zF8+HAcPXqUo343w79tcopbi7uMWq3G9evXAQCnT5++42Nvd/LkSQDA4cOH0aJFCzRr1gwdO3bE2rVr8cUXX6BPnz7WaZvKthcZGYnDhw8DAJKSkhAUFFTla0VGRlpfLzU1FZMmTSr3fJ1Oh+Tk5HJrvdzJqVOnAJQurKfT6RAcHAydTofMzEwAwMGDB3HvvfdWmb1Zs2aYPHky1q5di7lz56J3795VPlapVEKSJADA+vXrMX78eKxbtw4AsG3btmrlpbqBc/7kMl544QXMnTsXoaGh1pOgVNf27dvxxRdfwMfHB0uWLIGfnx8OHjyI559/HkVFRXjsscfKraV+uylTpmDWrFn4/PPPYTabsWDBgiofO2TIEMyYMQPDhw+HxWLBjBkz0LJlS8yaNQtDhw6FwWDAuHHjEBgYWK3sWVlZePHFF1FYWIjZs2dDpVJh/vz5GD9+PBQKBerXr49FixZZR/+3mzp1KubMmQODwYCSkhLMnDmzytcKCwtDcnIy1qxZg7Zt2+LVV1+Fj48PvL290bVr12rlpbqBC7sROdHGjRtx8eJFTJ482dlRyM1w2oeIyA1x5E9E5IY48icickMsfyIiN8TyJyJyQyx/IiI3xPInInJD/w9RjpTn6q1N/QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Principal Component Analysis\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "pca.fit(X_train)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9829937212606565"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cumsum(pca.explained_variance_ratio_)[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pca = PCA(n_components=200)\n",
    "final_pca.fit(X_train)\n",
    "X_train_pca = final_pca.transform(X_train)\n",
    "X_train_pca = pd.DataFrame(data = X_train_pca)\n",
    "X_test_pca = final_pca.transform(X_test)\n",
    "X_test_pca = pd.DataFrame(data = X_test_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "\n",
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regressiont Performance on the test set: Cross Validation Score = 0.6617\n"
     ]
    }
   ],
   "source": [
    "#Fitting Logistic Regression to training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "log_model = LogisticRegression()\n",
    "log_model.fit(X_train_pca, y_train)\n",
    "\n",
    "accuracies = cross_val_score(estimator = log_model, X = X_train_pca, y = y_train, cv = 5)\n",
    "random_cross = accuracies.mean()\n",
    "print('Logistic Regressiont Performance on the test set: Cross Validation Score = %0.4f' % random_cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= log_model.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted non-default (0)</th>\n",
       "      <th>Predicted default (1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual non-default (0)</th>\n",
       "      <td>12235</td>\n",
       "      <td>7054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual default (1)</th>\n",
       "      <td>5856</td>\n",
       "      <td>13131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Predicted non-default (0)  Predicted default (1)\n",
       "Actual non-default (0)                      12235                   7054\n",
       "Actual default (1)                           5856                  13131"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics as sm\n",
    "cmatrix = pd.DataFrame(sm.confusion_matrix(y_test, y_pred), index=['Actual non-default (0)','Actual default (1)'])\n",
    "cmatrix.columns = ['Predicted non-default (0)','Predicted default (1)']\n",
    "cmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The accuracy on the test data is 66.27%']\n"
     ]
    }
   ],
   "source": [
    "print([\"The accuracy on the test data is \" + str(round(sm.accuracy_score(y_test, y_pred)*100,ndigits = 2)) + \"%\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score is : 0.663\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(\"F1 score is :\",round(f1_score(y_test, y_pred, average='macro'),3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Performance on the test set: Cross Validation Score = 0.9921\n"
     ]
    }
   ],
   "source": [
    "# # Random Forest Classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random = RandomForestClassifier(n_estimators = 10, criterion = 'entropy')\n",
    "random.fit(X_train_pca, y_train)\n",
    "\n",
    "accuracies = cross_val_score(estimator = random, X = X_train_pca, y = y_train, cv = 5)\n",
    "random_cross = accuracies.mean()\n",
    "print('Random Forest Performance on the test set: Cross Validation Score = %0.4f' % random_cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_pred = random.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted non-default (0)</th>\n",
       "      <th>Predicted default (1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual non-default (0)</th>\n",
       "      <td>19191</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual default (1)</th>\n",
       "      <td>27</td>\n",
       "      <td>18960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Predicted non-default (0)  Predicted default (1)\n",
       "Actual non-default (0)                      19191                     98\n",
       "Actual default (1)                             27                  18960"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics as sm\n",
    "cmatrix = pd.DataFrame(sm.confusion_matrix(y_test, random_pred), index=['Actual non-default (0)','Actual default (1)'])\n",
    "cmatrix.columns = ['Predicted non-default (0)','Predicted default (1)']\n",
    "cmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The accuracy on the test data is 99.67%']\n"
     ]
    }
   ],
   "source": [
    "print([\"The accuracy on the test data is \" + str(round(sm.accuracy_score(y_test, random_pred)*100,ndigits = 2)) + \"%\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score is : 0.997\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 score is :\",round(f1_score(y_test, random_pred, average='macro'),3)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Performance on the test set: Cross Validation Score = 0.9310\n"
     ]
    }
   ],
   "source": [
    "#Fitting Decision Tree to training set\n",
    "from sklearn import tree\n",
    "dtree = tree.DecisionTreeClassifier()\n",
    "dtree.fit(X_train_pca, y_train)\n",
    "\n",
    "accuracies = cross_val_score(estimator = dtree, X = X_train_pca, y = y_train, cv = 5)\n",
    "random_cross = accuracies.mean()\n",
    "print('Decision Tree Performance on the test set: Cross Validation Score = %0.4f' % random_cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_pred = random.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted non-default (0)</th>\n",
       "      <th>Predicted default (1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual non-default (0)</th>\n",
       "      <td>19191</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual default (1)</th>\n",
       "      <td>27</td>\n",
       "      <td>18960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Predicted non-default (0)  Predicted default (1)\n",
       "Actual non-default (0)                      19191                     98\n",
       "Actual default (1)                             27                  18960"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics as sm\n",
    "cmatrix = pd.DataFrame(sm.confusion_matrix(y_test, dtree_pred), index=['Actual non-default (0)','Actual default (1)'])\n",
    "cmatrix.columns = ['Predicted non-default (0)','Predicted default (1)']\n",
    "cmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The accuracy on the test data is 99.67%']\n"
     ]
    }
   ],
   "source": [
    "print([\"The accuracy on the test data is \" + str(round(sm.accuracy_score(y_test, dtree_pred)*100,ndigits = 2)) + \"%\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score is : 0.997\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 score is :\",round(f1_score(y_test, dtree_pred, average='macro'),3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
